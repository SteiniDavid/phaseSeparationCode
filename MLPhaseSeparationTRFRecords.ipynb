{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from random import shuffle\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "LastFramePicture_path = 'LFPICS/*.png'\n",
    "\n",
    "# read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(LastFramePicture_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phaseSep = np.load('phaseSep.npy')\n",
    "labels = phaseSep #0 = Not Phase Separated  1 = Phase Separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "\n",
    "# Divide the hata into 60% train, 20% validation, and 20% test\n",
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "\n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(addr):\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)\n",
    "    return img\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/648\n",
      "Train data: 100/648\n",
      "Train data: 200/648\n",
      "Train data: 300/648\n",
      "Train data: 400/648\n",
      "Train data: 500/648\n",
      "Train data: 600/648\n"
     ]
    }
   ],
   "source": [
    "train_filename = 'train.tfrecords'  # address to save the TFRecords file\n",
    "# open the TFRecords file\n",
    "writer = tf.python_io.TFRecordWriter(train_filename)\n",
    "for i in range(len(train_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if not i % 100:\n",
    "        print 'Train data: {}/{}'.format(i, len(train_addrs))\n",
    "        sys.stdout.flush()\n",
    "    # Load the image\n",
    "    img = load_image(train_addrs[i])\n",
    "    label = train_labels[i]\n",
    "    # Create a feature\n",
    "    feature = {'train/label': _int64_feature(label),\n",
    "               'train/image': _bytes_feature(tf.compat.as_bytes(img.tostring()))}\n",
    "    # Create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "    # Serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "writer.close()\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val data: 0/216\n",
      "Val data: 100/216\n",
      "Val data: 200/216\n",
      "Test data: 0/216\n",
      "Test data: 100/216\n",
      "Test data: 200/216\n"
     ]
    }
   ],
   "source": [
    "# open the TFRecords file\n",
    "val_filename = 'val.tfrecords'  # address to save the TFRecords file\n",
    "writer = tf.python_io.TFRecordWriter(val_filename)\n",
    "\n",
    "for i in range(len(val_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if not i % 100:\n",
    "        print 'Val data: {}/{}'.format(i, len(val_addrs))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Load the image\n",
    "    img = load_image(val_addrs[i])\n",
    "\n",
    "    label = val_labels[i]\n",
    "\n",
    "    # Create a feature\n",
    "    feature = {'val/label': _int64_feature(label),\n",
    "               'val/image': _bytes_feature(tf.compat.as_bytes(img.tostring()))}\n",
    "\n",
    "    # Create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    # Serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "sys.stdout.flush()\n",
    "\n",
    "# open the TFRecords file\n",
    "test_filename = 'test.tfrecords'  # address to save the TFRecords file\n",
    "writer = tf.python_io.TFRecordWriter(test_filename)\n",
    "\n",
    "for i in range(len(test_addrs)):\n",
    "    # print how many images are saved every 1000 images\n",
    "    if not i % 100:\n",
    "        print 'Test data: {}/{}'.format(i, len(test_addrs))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Load the image\n",
    "    img = load_image(test_addrs[i])\n",
    "\n",
    "    label = test_labels[i]\n",
    "\n",
    "    # Create a feature\n",
    "    feature = {'test/label': _int64_feature(label),\n",
    "               'test/image': _bytes_feature(tf.compat.as_bytes(img.tostring()))}\n",
    "\n",
    "    # Create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "    # Serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 0 0 0]\n",
      "('LFPICS/final_tstep_pa80_pb120_xa30.png', 'LFPICS/final_tstep_pa20_pb130_xa90.png', 'LFPICS/final_tstep_pa30_pb140_xa10.png', 'LFPICS/final_tstep_pa30_pb70_xa50.png', 'LFPICS/final_tstep_pa90_pb150_xa20.png', 'LFPICS/final_tstep_pa40_pb120_xa70.png', 'LFPICS/final_tstep_pa30_pb60_xa10.png', 'LFPICS/final_tstep_pa50_pb120_xa20.png', 'LFPICS/final_tstep_pa10_pb80_xa30.png')\n"
     ]
    }
   ],
   "source": [
    "#35, 25, 30\n",
    "print phaseSep[1:10]\n",
    "print addrs[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
